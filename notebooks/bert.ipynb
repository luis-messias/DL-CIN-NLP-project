{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ratting prediction using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luism/anaconda3/envs/npl-esp/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet(Dataset):\n",
    "    def __init__(self, example=\"train\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "        if example == \"train\":\n",
    "            dataset = pd.read_csv('../Kaggle-dataset/pre-processed/trainDataset.csv',encoding=\"latin1\")\n",
    "        elif example == \"val\":\n",
    "            dataset = pd.read_csv('../Kaggle-dataset/pre-processed/valDataset.csv',encoding=\"latin1\")\n",
    "        else:\n",
    "            dataset = pd.read_csv('../Kaggle-dataset/pre-processed/testDataset.csv',encoding=\"latin1\")\n",
    "\n",
    "        self.text_data = dataset[\"textFull\"]\n",
    "        self.tokens = self.tokenizer(list(dataset[\"textFull\"]), padding = True, truncation=True)\n",
    "        self.labels = dataset[\"rating\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {}\n",
    "        for k, v in self.tokens.items():\n",
    "            item[k] = torch.tensor(v[idx]).to(device)\n",
    "        item['labels'] = torch.tensor(self.labels[idx]).to(device) - 1\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 300\n",
    "train_dataset = MyDataSet(example = \"train\")\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "val_dataset = MyDataSet(example = \"val\")\n",
    "val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_dataset = MyDataSet(example = \"test\")\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=5).to(device)\n",
    "bert.bert.requires_grad_(False)\n",
    "bert.classifier.requires_grad_(True)\n",
    "optimizer = torch.optim.AdamW(bert.parameters(), lr=1e-5) \n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 ----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [18:29,  6.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 304.8726934194565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [21:09<1:24:39, 1269.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:  39.99535322189331\n",
      "Val Acuracy:  0.5492767835253739\n",
      "Epoch:  2 ----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [18:24,  6.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 243.0159970521927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [42:16<1:03:23, 1267.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:  35.82822549343109\n",
      "Val Acuracy:  0.5496445207158618\n",
      "Epoch:  3 ----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [18:18,  6.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 229.95658695697784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [1:03:16<42:09, 1264.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:  34.887364864349365\n",
      "Val Acuracy:  0.5496445207158618\n",
      "Epoch:  4 ----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [18:18,  6.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 226.80657649040222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [1:24:15<21:02, 1262.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:  34.854777097702026\n",
      "Val Acuracy:  0.5493993625888698\n",
      "Epoch:  5 ----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 182 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [18:20,  6.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 226.53083562850952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [1:45:15<00:00, 1263.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss:  34.647578835487366\n",
      "Val Acuracy:  0.5492767835253739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "num_epochs = 5\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    print(\"Epoch: \",(epoch + 1), \"----------------------------------\")\n",
    "    bert.train()\n",
    "    total_loss_train = 0\n",
    "    for i,batch in tqdm(enumerate(train_loader)):\n",
    "        if i % 20 == 0:\n",
    "            print(i, len((train_loader)), end=\" \")\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        outputs = bert(input_ids = batch['input_ids'], attention_mask = batch['attention_mask'])\n",
    "        \n",
    "        pred = outputs.logits\n",
    "        loss = loss_fn(pred, batch['labels'])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss_train += loss.item()\n",
    "    print(f\"Train loss: {total_loss_train}\")\n",
    "\n",
    "    bert.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss_val = 0\n",
    "    for i, batch in enumerate(val_loader):\n",
    "        with torch.no_grad():\n",
    "            outputs = bert(input_ids = batch['input_ids'], attention_mask = batch['attention_mask'])\n",
    "        logits = outputs.logits\n",
    "        loss = loss_fn(logits, batch['labels'])\n",
    "        total_loss_val += loss.item()\n",
    "        \n",
    "        correct += (logits.argmax(1) == batch['labels']).sum().item()\n",
    "        total += (logits.argmax(1) == logits.argmax(1)).sum().item()\n",
    "    print(f\"Val loss: \",total_loss_val)\n",
    "    print(f\"Val Acuracy: \",correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('bert/bert.pkl','wb') as f:\n",
    "    pickle.dump(bert,f)\n",
    "with open('bert/tokenizer.pkl','wb') as f:\n",
    "    pickle.dump(AutoTokenizer.from_pretrained(\"bert-base-cased\"),f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(embedding, svm, X):\n",
    "    X_embedding = [embedding(x).vector for x in X]\n",
    "    return svm.predict(X_embedding)\n",
    "\n",
    "Y_val = valDataSet[\"rating\"]\n",
    "Y_val_pred = predict(embedding, svm, valDataSet[\"textFull\"])\n",
    "Y_test = testDataSet[\"rating\"]\n",
    "Y_test_pred = predict(embedding, svm, testDataSet[\"textFull\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val\n",
      "\tAcuracia:  0.6518754596714881\n",
      "\tF1:  [0.59674389 0.04761905 0.03826087 0.13442325 0.78011332]\n",
      "Test\n",
      "\tAcuracia:  0.659375\n",
      "\tF1:  [0.5943304  0.02083333 0.03743316 0.15555556 0.78945939]\n"
     ]
    }
   ],
   "source": [
    "acc_val = sklearn.metrics.accuracy_score(Y_val, Y_val_pred)\n",
    "f1_val = sklearn.metrics.f1_score(Y_val, Y_val_pred, average=None)\n",
    "acc_test = sklearn.metrics.accuracy_score(Y_test, Y_test_pred)\n",
    "f1_test = sklearn.metrics.f1_score(Y_test, Y_test_pred, average=None)\n",
    "\n",
    "print(\"Val\")\n",
    "print(\"\\tAcuracia: \", acc_val)\n",
    "print(\"\\tF1: \", f1_val)\n",
    "\n",
    "print(\"Test\")\n",
    "print(\"\\tAcuracia: \", acc_test)\n",
    "print(\"\\tF1: \", f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please read amazing phone wish couldve used really research phone wa excited purchase made amazon unfortunately next day received phone thats nightmare started phone looked brand new sealed packaging like would purchase store example literally use scissors cut packing even get provided book cut complete different package even touch phone went proper procedure activating phone purchasing bundle plan use phone wa completely done programming customer service rep tell make call error message stated phone authenticated happened february 27th today march 3 2014 learned return phone amazon tthis review customer beware purpose amazon verizon wireless excellent customer service tried hard fix issue crazy part learned tonight phone purchased actually hacked never able use granted wa upset almost week late night verizon rep wa getting old trying million thing repeatedly try fix phone tonight verizon rep told straight maam need return phone somebody ha hacked phone resold whatever site bought wa shocked told exactly packaging wa literally argued thought wa nut wa telling truth even promised full bundle applied new phone get contacted amazon amazing refunded money sent shipping label easy return always shop online first time anything crazy ha happened worth mentioning customer know\n",
      "Original:  5\n",
      "Predict:  1\n"
     ]
    }
   ],
   "source": [
    "example = 33\n",
    "print(testDataSet.iloc[example][\"textFull\"])\n",
    "print( \"Original: \", Y_test[example])\n",
    "print(\"Predict: \", Y_test_pred[example])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "npl-esp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
